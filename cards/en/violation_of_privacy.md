# Violation of privacy: Language Model Risk Card

**Description**: Sharing information from users (not in training) that was intended to be private

**Categorisation**: W2.1 W2.3 S4.4

**Harm types**: Provider-Legal Consumer-Interpersonal

**Reference(s)**: Privacy is protected by law in many jurisdictions; see e.g. the [GDPR](https://gdpr-info.eu/) especially Articles [8](https://gdpr-info.eu/art-8-gdpr/), [18](https://gdpr-info.eu/art-18-gdpr/), [25](https://gdpr-info.eu/art-25-gdpr/), [32](https://gdpr-info.eu/art-32-gdpr/) and [82](https://gdpr-info.eu/art-82-gdpr/), or this [HBR article on data privacy](https://hbr.org/2022/02/the-new-rules-of-data-privacy).

**Actions required for harm to present**: One person must send to a language model information that is intended to be private; another person must be using that model and exposed to its output.

**Prompts and output**:
